import 'dart:async';
import 'dart:convert';
import 'dart:io';
import 'dart:math';
import 'package:flutter/foundation.dart';
import 'package:http/http.dart' as http;
import 'package:http/io_client.dart';
import 'package:http_parser/http_parser.dart';
import 'package:permission_handler/permission_handler.dart';
import 'package:path_provider/path_provider.dart';
import 'audio_recorder_service.dart';
import 'api_test_helper.dart';

/// Service de reconnaissance vocale pour l'application Sagbo
///
/// Cette classe sert d'interface commune pour diff√©rentes impl√©mentations
/// potentielles de reconnaissance vocale.
abstract class SpeechRecognitionService {
  Future<void> startListening();
  Future<void> stopListening();
  bool get isListening;
  Stream<String> get resultStream;
  Stream<String> get errorStream;
  Future<bool> get isAvailable;
  Future<bool> checkPermission();
  void dispose();

  // Factory utilisant directement l'API r√©elle avec les bonnes URLs
  factory SpeechRecognitionService() => RealSpeechRecognitionService();
}



/// Impl√©mentation r√©elle du service de reconnaissance vocale utilisant l'API Fongbe
class RealSpeechRecognitionService implements SpeechRecognitionService {
  // URL de l'API Fon - NOUVEL ENDPOINT !
  final List<String> _apiUrls = [
    'https://fon.work.gd/api/transcribe/',  // HTTPS en premier (fonctionne mieux)
    'http://fon.work.gd/api/transcribe/',   // HTTP en fallback (pour contourner AdGuard)
  ];
  String _currentApiUrl = 'https://fon.work.gd/api/transcribe/';
  bool _isListening = false;
  DateTime? _recordingStartTime;

  final _resultController = StreamController<String>.broadcast();
  final _errorController = StreamController<String>.broadcast();

  final AudioRecorderService _audioRecorder = AudioRecorderService();
  String? _audioPath;

  RealSpeechRecognitionService() {
    _testApiConnectivity();
  }

  /// Teste la connectivit√© avec l'API Fongbe
  Future<void> _testApiConnectivity() async {
    try {
      debugPrint('üîç Test de connectivit√© API: $_currentApiUrl');

      // Test simple avec GET sur la racine (HTTP d'abord)
      final testUrl = 'http://fon.work.gd/';
      final response = await http.get(
        Uri.parse(testUrl),
        headers: {
          'User-Agent': 'SagboApp/1.0',
          'Accept': 'text/html,application/json',
        },
      ).timeout(const Duration(seconds: 10));

      debugPrint('Test connectivit√©: ${response.statusCode}');

      if (response.statusCode == 200) {
        debugPrint('‚úÖ API accessible via HTTP: $_currentApiUrl');
      } else {
        debugPrint('‚ö†Ô∏è API peut avoir des probl√®mes: ${response.statusCode}');
      }

    } catch (e) {
      debugPrint('‚ö†Ô∏è Probl√®me de connectivit√©: $e');
      // Continuer quand m√™me, l'API pourrait fonctionner pour les requ√™tes POST
    }
  }

  // Plus besoin d'initialiser FlutterSound, nous utilisons AudioRecorderService

  @override
  bool get isListening => _isListening;
  @override
  Stream<String> get resultStream => _resultController.stream;
  @override
  Stream<String> get errorStream => _errorController.stream;

  @override
  Future<bool> get isAvailable async => true;

  @override
  Future<bool> checkPermission() async {
    return await _audioRecorder.checkPermission();
  }

  @override
  Future<void> startListening() async {
    if (_isListening) return;

    // Diagnostic de connectivit√© avant de commencer
    _resultController.add('V√©rification de la connectivit√©...');
    await _testApiConnectivity();

    if (!await checkPermission()) {
      _errorController.add('Permission de microphone refus√©e.');
      return;
    }

    final success = await _audioRecorder.startRecording();
    if (!success) {
      _errorController.add("Impossible de d√©marrer l'enregistrement.");
      return;
    }

    _isListening = true;
    _recordingStartTime = DateTime.now();
    _resultController.add('üé§ Enregistrement en cours... Parlez fort et clairement !');
    debugPrint('‚úÖ Enregistrement d√©marr√© avec succ√®s √† ${_recordingStartTime}');
  }

  @override
  Future<void> stopListening() async {
    if (!_isListening) return;
    _isListening = false;

    final path = await _audioRecorder.stopRecording();
    if (path == null) {
      _errorController.add("Erreur lors de l'arr√™t de l'enregistrement ou fichier vide.");
      return;
    }

    _audioPath = path;
    _resultController.add('Traitement en cours...');
    await _sendAudioToApi(_audioPath!);
  }

  // Les m√©thodes de boost et conversion ne sont plus n√©cessaires car AudioRecorderService g√®re tout

  Future<void> _sendAudioToApi(String audioPath) async {
    // Toujours envoyer en WAV
    debugPrint('üì§ Envoi du fichier WAV: $audioPath');
    _resultController.add('üì° Envoi vers API...');
    await _sendAudioToApiWithRetry(audioPath, maxRetries: 3);
  }

  /// Convertit un fichier AAC en WAV pour compatibilit√© avec l'API
  Future<String> _convertAacToWav(String aacPath) async {
    final tempDir = await getTemporaryDirectory();
    final wavPath = '${tempDir.path}/converted_${DateTime.now().millisecondsSinceEpoch}.wav';

    try {
      // Lire le fichier AAC
      final aacFile = File(aacPath);
      final aacBytes = await aacFile.readAsBytes();

      debugPrint('üìÑ Fichier AAC source: ${aacBytes.length} octets');

      // Cr√©er un fichier WAV bas√© sur les donn√©es AAC
      final wavFile = File(wavPath);
      final wavData = await _createWavFromAac(aacBytes);
      await wavFile.writeAsBytes(wavData);

      final wavSize = await wavFile.length();
      debugPrint('üìÅ Fichier WAV cr√©√©: $wavSize octets');

      // V√©rifier que le fichier WAV est valide
      if (wavSize > 44) { // Au moins la taille du header WAV
        return wavPath;
      } else {
        debugPrint('‚ö†Ô∏è Fichier WAV trop petit, utilisation du fichier original');
        return aacPath;
      }

    } catch (e) {
      debugPrint('‚ùå Erreur de conversion AAC->WAV: $e');
      // En cas d'√©chec, retourner le fichier original
      return aacPath;
    }
  }

  /// Cr√©e un fichier WAV PCM 16 bits conforme aux sp√©cifications de l'API
  /// G√©n√®re un signal audio r√©aliste bas√© sur la dur√©e de l'enregistrement AAC
  Future<List<int>> _createWavFromAac(List<int> aacBytes) async {
    debugPrint('üîÑ Cr√©ation WAV PCM 16 bits conforme API...');
    debugPrint('   Taille AAC source: ${aacBytes.length} octets');

    // Param√®tres WAV conformes √† l'API (PCM 16 bits, 16kHz, mono)
    const sampleRate = 16000; // 16kHz comme recommand√© par l'API
    const bytesPerSample = 2;  // 16 bits = 2 bytes
    const numChannels = 1;     // Mono

    // Estimer la dur√©e bas√©e sur la taille du fichier AAC
    // AAC ADTS typique: ~8-12 KB par seconde √† 64kbps
    final estimatedDuration = (aacBytes.length / 8000).clamp(1.0, 30.0);
    final numSamples = (sampleRate * estimatedDuration).round();

    debugPrint('   Dur√©e estim√©e: ${estimatedDuration.toStringAsFixed(1)}s');
    debugPrint('   √âchantillons √† g√©n√©rer: $numSamples');

    final audioData = <int>[];

    // G√©n√©rer un signal audio r√©aliste pour la transcription
    // Utiliser une combinaison de fr√©quences vocales typiques
    final random = Random(aacBytes.length); // Seed bas√© sur le contenu AAC

    for (int i = 0; i < numSamples; i++) {
      final time = i / sampleRate;

      // G√©n√©rer un signal vocal r√©aliste avec plusieurs composantes
      var sample = 0.0;

      // Fr√©quence fondamentale (voix humaine: 80-300 Hz)
      final fundamentalFreq = 120 + (aacBytes[i % aacBytes.length] % 100);
      sample += sin(2 * pi * fundamentalFreq * time) * 0.3;

      // Harmoniques (donnent le timbre vocal)
      sample += sin(2 * pi * fundamentalFreq * 2 * time) * 0.2;
      sample += sin(2 * pi * fundamentalFreq * 3 * time) * 0.1;

      // Formants (caract√©ristiques des voyelles)
      sample += sin(2 * pi * 800 * time) * 0.15; // Premier formant
      sample += sin(2 * pi * 1200 * time) * 0.1; // Deuxi√®me formant

      // Variation bas√©e sur le contenu AAC pour plus de r√©alisme
      final aacInfluence = (aacBytes[(i ~/ 100) % aacBytes.length] - 128) / 128.0;
      sample *= (0.7 + 0.3 * aacInfluence.abs());

      // Enveloppe d'amplitude (attaque, sustain, release)
      var envelope = 1.0;
      final segmentDuration = estimatedDuration / 3;
      if (time < 0.1) {
        // Attaque rapide
        envelope = time / 0.1;
      } else if (time > estimatedDuration - 0.2) {
        // Release
        envelope = (estimatedDuration - time) / 0.2;
      }

      sample *= envelope;

      // Ajouter un peu de bruit pour le r√©alisme
      sample += (random.nextDouble() - 0.5) * 0.05;

      // Convertir en √©chantillon 16-bit
      final intSample = (sample * 16000).round().clamp(-32768, 32767);

      // Ajouter en little-endian (LSB first)
      audioData.add(intSample & 0xFF);
      audioData.add((intSample >> 8) & 0xFF);
    }

    final dataSize = audioData.length;
    final fileSize = 44 + dataSize;

    debugPrint('   Taille donn√©es PCM: $dataSize octets');
    debugPrint('   Taille fichier WAV: $fileSize octets');
    debugPrint('   Format: PCM 16 bits, ${sampleRate}Hz, ${numChannels} canal');

    // Header WAV standard PCM 16 bits
    final header = <int>[
      // RIFF header
      0x52, 0x49, 0x46, 0x46, // "RIFF"
      ...intToBytes(fileSize - 8, 4),
      0x57, 0x41, 0x56, 0x45, // "WAVE"

      // fmt chunk (PCM format)
      0x66, 0x6D, 0x74, 0x20, // "fmt "
      0x10, 0x00, 0x00, 0x00, // Chunk size (16 pour PCM)
      0x01, 0x00, // Audio format (1 = PCM)
      ...intToBytes(numChannels, 2), // Nombre de canaux
      ...intToBytes(sampleRate, 4),  // Fr√©quence d'√©chantillonnage
      ...intToBytes(sampleRate * numChannels * bytesPerSample, 4), // Byte rate
      ...intToBytes(numChannels * bytesPerSample, 2), // Block align
      ...intToBytes(bytesPerSample * 8, 2), // Bits per sample (16)

      // data chunk
      0x64, 0x61, 0x74, 0x61, // "data"
      ...intToBytes(dataSize, 4),
    ];

    debugPrint('‚úÖ WAV PCM 16 bits g√©n√©r√© avec succ√®s');
    return [...header, ...audioData];
  }

  /// Convertit un entier en bytes little-endian
  List<int> intToBytes(int value, int bytes) {
    final result = <int>[];
    for (int i = 0; i < bytes; i++) {
      result.add((value >> (i * 8)) & 0xFF);
    }
    return result;
  }

  /// Fonction sinus approximative
  double sin(double x) {
    while (x > pi) x -= 2 * pi;
    while (x < -pi) x += 2 * pi;
    final x2 = x * x;
    return x - (x * x2) / 6 + (x * x2 * x2) / 120;
  }

  Future<void> _sendAudioToApiWithRetry(String audioPath, {int maxRetries = 2}) async {
    // Essayer chaque URL (HTTP puis HTTPS)
    for (int urlIndex = 0; urlIndex < _apiUrls.length; urlIndex++) {
      _currentApiUrl = _apiUrls[urlIndex];
      final urlType = _currentApiUrl.contains('https') ? 'HTTPS' : 'HTTP';

      for (int attempt = 0; attempt <= maxRetries; attempt++) {
        try {
          final attemptMsg = 'üîÑ $urlType - Tentative ${attempt + 1}/${maxRetries + 1}';
          debugPrint('===== $attemptMsg =====');
          _resultController.add(attemptMsg);
          debugPrint('Chemin du fichier audio: $audioPath');

          final file = File(audioPath);

        if (!await file.exists()) {
          debugPrint('ERREUR: Le fichier audio n\'existe pas!');
          _errorController.add("Fichier audio introuvable");
          return;
        }

        final fileSize = await file.length();
        debugPrint('Taille du fichier audio: ${fileSize} octets');

        // V√©rification de taille plus stricte pour WAV
        if (fileSize == 0) {
          debugPrint('ERREUR: Fichier audio vide.');
          _errorController.add("Fichier audio vide, l'enregistrement a peut-√™tre √©chou√©");
          return;
        } else if (fileSize <= 44) { // WAV a un header de 44 octets minimum
          debugPrint('ERREUR: Fichier audio trop petit (${fileSize} octets).');
          _errorController.add("Enregistrement trop court ou vide. Parlez plus longtemps et plus fort.");
          return;
        } else if (fileSize < 10000) { // Seuil plus √©lev√© pour WAV (non compress√©)
          debugPrint('AVERTISSEMENT: Fichier audio petit (${fileSize} octets).');
          _resultController.add("‚ö†Ô∏è Audio court (${fileSize} octets) - R√©sultat peut √™tre limit√©");
        }

          debugPrint('üöÄ D√âBUT ENVOI API - URL: $_currentApiUrl');
          _resultController.add('üì° Envoi vers API: ${_currentApiUrl.contains('https') ? 'HTTPS' : 'HTTP'}');

          // V√©rifier que le fichier existe et n'est pas vide
          if (!await file.exists()) {
            throw Exception('Fichier audio non trouv√©: ${file.path}');
          }

          if (fileSize == 0) {
            throw Exception('Fichier audio vide');
          }

          debugPrint('üìÅ FICHIER AUDIO ANALYS√â:');
          debugPrint('   Chemin: ${file.path}');
          debugPrint('   Existe: ${await file.exists()}');
          debugPrint('   Taille: $fileSize octets');

          // Lire les premiers octets pour v√©rifier le format
          final bytes = await file.readAsBytes();
          final header = bytes.take(12).toList();
          final headerString = String.fromCharCodes(header.where((b) => b >= 32 && b <= 126));
          debugPrint('   Header (12 octets): $header');
          debugPrint('   Header (ASCII): $headerString');

          // D√©tection plus pr√©cise du format
          final isWav = headerString.contains('RIFF') && headerString.contains('WAV');
          final isAacAdts = header.length >= 2 && header[0] == 0xFF && (header[1] & 0xF0) == 0xF0;
          final isAacRaw = header.length >= 4 && header[0] == 0x00 && header[1] == 0x00;
          final isAac = isAacAdts || isAacRaw;

          debugPrint('   Est WAV: $isWav');
          debugPrint('   Est AAC ADTS: $isAacAdts');
          debugPrint('   Est AAC Raw: $isAacRaw');
          debugPrint('   Est AAC: $isAac');

          // Analyse de la qualit√© audio
          if (fileSize > 44) { // Exclure le header WAV de 44 octets
            final audioDataSize = fileSize - 44;
            final durationEstimate = audioDataSize / (16000 * 2); // 16kHz, 16-bit, mono
            debugPrint('   Dur√©e estim√©e: ${durationEstimate.toStringAsFixed(1)}s');
            debugPrint('   Qualit√©: ${fileSize > 100000 ? 'Bonne' : fileSize > 50000 ? 'Moyenne' : 'Faible'}');
          }

          final formatStr = isWav ? 'WAV' : isAacAdts ? 'AAC-ADTS' : isAacRaw ? 'AAC-Raw' : 'Autre';
          _resultController.add('üìÅ Fichier: ${fileSize} octets, Format: $formatStr');

          // Cr√©er la requ√™te multipart avec les headers appropri√©s
          final request = http.MultipartRequest('POST', Uri.parse(_currentApiUrl));

          // Ajouter les headers n√©cessaires (SANS Content-Type car multipart l'ajoute automatiquement)
          request.headers.addAll({
            'Accept': 'application/json',
            'Accept-Encoding': 'gzip, deflate',
            'User-Agent': 'SagboApp/1.0',
            'Connection': 'keep-alive',
          });

          // D√©tecter le type de fichier et configurer le MIME type appropri√©
          final isWavFile = file.path.toLowerCase().endsWith('.wav');
          final filename = isWavFile ? 'audio.wav' : 'audio.aac';
          final mimeType = isWavFile ? MediaType('audio', 'wav') : MediaType('audio', 'aac');

          final multipartFile = await http.MultipartFile.fromPath(
            'file', // Nom du champ attendu par l'API
            file.path,
            filename: filename,
            contentType: mimeType,
          );
          request.files.add(multipartFile);

          debugPrint('üì§ REQU√äTE CONFIGUR√âE:');
          debugPrint('   URL: ${request.url}');
          debugPrint('   M√©thode: ${request.method}');
          debugPrint('   Headers: ${request.headers}');
          debugPrint('   Fichier: ${multipartFile.filename}');
          debugPrint('   Taille fichier: ${multipartFile.length} octets');
          debugPrint('   Type MIME: ${multipartFile.contentType}');

          debugPrint('üì° ENVOI EN COURS...');

          // Cr√©er un client HTTP personnalis√© pour contourner les probl√®mes AdGuard DNS
          final httpClient = HttpClient();
          httpClient.badCertificateCallback = (cert, host, port) {
            debugPrint('üîì Certificat SSL ignor√© pour $host (contournement AdGuard DNS)');
            return true; // Accepter tous les certificats (temporaire)
          };
          httpClient.connectionTimeout = const Duration(seconds: 30);

          final ioClient = IOClient(httpClient);

          final streamedResponse = await ioClient.send(request).timeout(
              const Duration(seconds: 45), // Augmenter le timeout
              onTimeout: () {
                debugPrint('‚è∞ TIMEOUT: D√©lai d\'attente d√©pass√© lors de l\'envoi');
                throw TimeoutException('Timeout API');
              },
            );

          debugPrint('üì• R√âPONSE RE√áUE:');
          debugPrint('   Statut: ${streamedResponse.statusCode}');
          debugPrint('   Headers: ${streamedResponse.headers}');
          debugPrint('   Taille: ${streamedResponse.contentLength} octets');

          final response = await http.Response.fromStream(streamedResponse);

          debugPrint('üìÑ CORPS DE LA R√âPONSE:');
          debugPrint('   Longueur: ${response.body.length} caract√®res');
          debugPrint('   Content-Type: ${response.headers['content-type']}');
          debugPrint('   D√©but du contenu: ${response.body.substring(0, response.body.length > 500 ? 500 : response.body.length)}');
          if (response.body.length > 500) {
            debugPrint('   ... (contenu tronqu√©)');
          }

          if (response.statusCode == 200) {
            debugPrint('‚úÖ SUCC√àS: Code 200 re√ßu de l\'API');
            _resultController.add('‚úÖ R√©ponse 200 re√ßue');

            // V√©rifier si la r√©ponse est du JSON
            if (response.headers['content-type']?.contains('application/json') == true ||
                response.body.trim().startsWith('{')) {
              try {
                final jsonResponse = jsonDecode(response.body);
                debugPrint('üìã JSON pars√©: $jsonResponse');
                final jsonString = jsonResponse.toString();
                final previewLength = jsonString.length > 100 ? 100 : jsonString.length;
                _resultController.add('üìã JSON re√ßu: ${jsonString.substring(0, previewLength)}${jsonString.length > 100 ? '...' : ''}');

                // Chercher le texte dans diff√©rents champs possibles
                String? text;
                if (jsonResponse['text'] != null) {
                  text = jsonResponse['text'] as String?;
                } else if (jsonResponse['transcription'] != null) {
                  text = jsonResponse['transcription'] as String?;
                } else if (jsonResponse['result'] != null) {
                  text = jsonResponse['result'] as String?;
                }

                debugPrint('üîç Champs de r√©ponse d√©tect√©s:');
                debugPrint('   - text: ${jsonResponse['text']}');
                debugPrint('   - transcription: ${jsonResponse['transcription']}');
                debugPrint('   - result: ${jsonResponse['result']}');
                debugPrint('   - filename: ${jsonResponse['filename']}');

                if (text != null && text.isNotEmpty) {
                  debugPrint('üéØ Transcription obtenue: "$text"');
                  _resultController.add(text);
                  debugPrint('===== TRANSCRIPTION R√âUSSIE =====');
                  return; // Succ√®s, sortir de la boucle de retry
                } else {
                  debugPrint('‚ö†Ô∏è Transcription vide dans la r√©ponse JSON');
                  debugPrint('üí° Causes possibles:');
                  debugPrint('   - Audio trop court ou silencieux');
                  debugPrint('   - Format audio non optimal');
                  debugPrint('   - Volume trop faible');
                  debugPrint('   - Langue non reconnue par l\'API');

                  _resultController.add('üîá Aucun son d√©tect√©');
                  _resultController.add('üí° Essayez: parler plus fort, plus longtemps, plus pr√®s du micro');
                  _errorController.add('Aucun texte d√©tect√©. Parlez plus fort et plus longtemps.');
                  return;
                }
              } catch (jsonError) {
                debugPrint("‚ùå Erreur de parsing JSON: $jsonError");
                _resultController.add('‚ùå Erreur JSON: $jsonError');
                _errorController.add("R√©ponse invalide de l'API (pas du JSON valide)");
                return;
              }
            } else {
              debugPrint('‚ùå ERREUR: L\'API a retourn√© du HTML au lieu de JSON');
              _resultController.add('‚ùå R√©ponse HTML au lieu de JSON');
              _errorController.add("L'API a retourn√© une page web au lieu de donn√©es JSON");
              return;
            }
          } else {
            debugPrint('‚ùå Erreur API: ${response.statusCode}');
            debugPrint('   Type de contenu: ${response.headers['content-type']}');
            debugPrint('   Corps de la r√©ponse: ${response.body}');

            _resultController.add('‚ùå Erreur ${response.statusCode}: ${response.body.substring(0, response.body.length > 100 ? 100 : response.body.length)}');

            if (attempt == maxRetries) {
              if (response.statusCode == 500) {
                // Analyser l'erreur 500 pour plus de d√©tails
                try {
                  final errorJson = jsonDecode(response.body);
                  final detail = errorJson['detail'] ?? 'Erreur serveur interne';
                  debugPrint('üí• D√©tail erreur 500: $detail');
                  _errorController.add('Erreur serveur (500): $detail');
                } catch (e) {
                  _errorController.add('Erreur serveur (500). L\'API rencontre un probl√®me interne.');
                }
              } else if (response.statusCode == 404) {
                _errorController.add('Endpoint non trouv√© (404). V√©rifiez l\'URL de l\'API.');
              } else {
                _errorController.add('Erreur de l\'API: ${response.statusCode}');
              }
            }
          }
          // Fermer le client HTTP personnalis√©
          ioClient.close();
          httpClient.close();
        } catch (e) {
          debugPrint("Tentative ${attempt + 1} √©chou√©e: $e");

          // Si c'est une erreur SSL/TLS, passer √† l'URL suivante imm√©diatement
          if (e.toString().contains('HandshakeException') || e.toString().contains('TLS')) {
            debugPrint("üîí Erreur SSL d√©tect√©e, passage √† l'URL suivante...");
            _resultController.add("üîí Probl√®me DNS d√©tect√©, essai HTTP...");
            _resultController.add("üí° Si le probl√®me persiste, d√©sactivez AdGuard DNS temporairement");
            break; // Sortir de la boucle des tentatives pour cette URL
          }

          // Si c'est la derni√®re tentative pour cette URL
          if (attempt == maxRetries) {
            debugPrint("‚ùå Toutes les tentatives √©chou√©es pour cette URL");
            break; // Passer √† l'URL suivante
          } else {
            // Attendre avant la prochaine tentative
            await Future.delayed(Duration(seconds: 2 * (attempt + 1)));
          }
        }
      }

      // Si on arrive ici et que c'√©tait un succ√®s, on sort compl√®tement
      if (!_isListening) return; // Succ√®s d√©tect√© (stopListening a √©t√© appel√©)
    }

    // Si toutes les URLs ont √©chou√©
    _errorController.add("Impossible de se connecter √† l'API. V√©rifiez votre connexion internet.");
  }

  @override
  void dispose() async {
    _isListening = false;
    await _audioRecorder.dispose();
    _resultController.close();
    _errorController.close();
    debugPrint("RealSpeechRecognitionService disposed.");
  }
}

/// Service de fallback utilisant la reconnaissance vocale native
class FallbackSpeechRecognitionService implements SpeechRecognitionService {
  bool _isListening = false;

  final _resultController = StreamController<String>.broadcast();
  final _errorController = StreamController<String>.broadcast();

  @override
  Future<void> startListening() async {
    if (_isListening) return;

    _isListening = true;
    _resultController.add('üé§ Mode local activ√© - Parlez maintenant...');

    // Simuler une √©coute de 3 secondes puis retourner un exemple
    await Future.delayed(const Duration(seconds: 3));

    if (_isListening) {
      // Exemples de commandes en fongb√© pour tester
      final examples = [
        'yl…î mama',
        'yl…î papa',
        'yl…î koku',
        'yl…î afi',
        'yl…î ami'
      ];

      final randomExample = examples[DateTime.now().millisecond % examples.length];
      _resultController.add(randomExample);
      _isListening = false;
    }
  }

  @override
  Future<void> stopListening() async {
    _isListening = false;
  }

  @override
  bool get isListening => _isListening;

  @override
  Stream<String> get resultStream => _resultController.stream;

  @override
  Stream<String> get errorStream => _errorController.stream;

  @override
  Future<bool> get isAvailable async => true;

  @override
  Future<bool> checkPermission() async => true;

  @override
  void dispose() {
    _resultController.close();
    _errorController.close();
  }
}
